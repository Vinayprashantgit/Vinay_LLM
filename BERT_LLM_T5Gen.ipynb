{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM/ZcTtACFB5oIcN3zkbt4R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"1i3pPrA48x-v"},"outputs":[],"source":["#Dependencies\n","pip install tensorflow transformers PyPDF2"]},{"cell_type":"code","source":["import tensorflow as tf\n","from transformers import BertTokenizer, TFBertForQuestionAnswering, T5ForConditionalGeneration, T5Tokenizer\n","import PyPDF2\n","import re\n","\n","def initialize_bert_model():\n","    model = TFBertForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n","    tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n","    return model, tokenizer\n","\n","def extract_text_from_pdf(pdf_path):\n","    text = \"\"\n","    with open(pdf_path, 'rb') as file:\n","        pdf_reader = PyPDF2.PdfReader(file)\n","        for page_num in range(len(pdf_reader.pages)):\n","            text += pdf_reader.pages[page_num].extract_text()\n","    return text\n","\n","def chunk_text(text, max_chunk_size=512):\n","    chunks = [text[i:i + max_chunk_size] for i in range(0, len(text), max_chunk_size)]\n","    return chunks\n","\n","def answer_question(document, question, model, tokenizer):\n","    inputs = tokenizer(question, document, return_tensors=\"tf\", max_length=512, truncation=True)\n","    outputs = model(inputs)\n","    start_logits = outputs.start_logits\n","    end_logits = outputs.end_logits\n","    start_idx = tf.argmax(start_logits, axis=1).numpy()[0]\n","    end_idx = tf.argmax(end_logits, axis=1).numpy()[0]\n","\n","    if 0 <= start_idx < len(inputs[\"input_ids\"].numpy()[0]) and 0 <= end_idx < len(inputs[\"input_ids\"].numpy()[0]):\n","        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].numpy()[0])\n","        answer = tokenizer.convert_tokens_to_string(tokens[start_idx:end_idx + 1])\n","        return answer\n","    else:\n","        return \"Answer not found\"\n","\n","def summarize_with_t5(text):\n","    model_name = \"t5-small\"\n","    tokenizer = T5Tokenizer.from_pretrained(model_name)\n","    model = T5ForConditionalGeneration.from_pretrained(model_name)\n","\n","    inputs = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n","    summary_ids = model.generate(inputs[\"input_ids\"], max_length=150, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n","\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary\n","\n","def main():\n","    pdf_path = \"/content/fundamentals_supplychain-1-4.pdf\"\n","    document = extract_text_from_pdf(pdf_path)\n","    document_chunks = chunk_text(document)\n","    question = input(\"Ask a question: \")\n","\n","    model, tokenizer = initialize_bert_model()\n","    all_answers = []\n","\n","    for i, chunk in enumerate(document_chunks):\n","        print(f\"Processing chunk {i + 1} of {len(document_chunks)}\")\n","        answer = answer_question(chunk, question, model, tokenizer)\n","        all_answers.append(answer)\n","\n","    final_answer = '\\n'.join(all_answers)\n","    t5_summary = summarize_with_t5(final_answer)\n","    print(f\"T5 Summarized Answer:\\n{t5_summary}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"id":"1mOsTZdK8zCP"},"execution_count":null,"outputs":[]}]}